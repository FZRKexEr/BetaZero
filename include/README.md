# C++ 实现的 神经网络 Monte Carlo tree search  

## BatchNeuralNetwork.hpp

实现了单个神经网络批量推理来自多个MCTS线程的predict请求

做到在N线程进行自我对弈的同时，速度和单线程基本一致

单次推理大概3ms

batchsize 和线程数一致

等待5ms如果没有足够的batchsize则直接开始执行推理任务，实际上只有在整个自我对弈快结束的时候才会触发这样的等待, 等待5ms影响也不是很大

## BoardGame.h

定义了一个通用的棋盘游戏接口, 大概黑白棋，五子棋，围棋，都可以用这个接口来实现

## Othello.hpp

实现了黑白棋的规则, 基于BoardGame.h

使用 uint64_t 来表示棋盘状态，位运算进行操作，整个实例占用内存很小，因为只存储几个 uint64_t

使用 zobrist Hash

## MCTS.hpp

实现了基础的蒙特卡洛树搜索算法, 主要是 search 函数部分

可以拓展实现随机走子评估的纯MCTS, 使用神经网络评估的MCTS

可以选择添加 Dirichlet Noise 

## ModelEvaluator.hpp

加载两个模型进行对弈，统计结果

可以多线程进行对局

在评估的时候，使用贪婪策略，不使用温度参数，发挥模型最大实力

后续训练放弃了使用这个模块，不在进行模型评估，选择相信最新的模型用来迭代就能一直提升实例。

关于这里我的思考是，其实对弈的结果很难评价两个相似模型的优劣，因为如果要发挥模型全部实力，就必须要尽可能少的引入随机性，尽可能让模型自己判断最优走子。但是模型的最优走子往往是固定的，所以多次对局的，只要执黑执白确定了，就会有固定的结果。如果引入随机性，这个随机的策略其实也是手工参数决定的，并不能保证能在各个局面下体现模型的优劣，而且损失了模型的实力。只有在两个模型相差很大的情况下，才能通过对局评估出优劣。所以后面的训练就没有使用评估，而是相信模型在更多的数据下迭代就能丰富模型处理各种局面的能力，模型会处于螺旋上升的状态。


## NeuralNetwork.hpp

不使用多线程的神经网络，用于推理MCTS新节点的 pi 和 v

## NeuralNetworkMCTS.hpp

调用神经网络进行推理的MCTS

具体来说和纯MCTS区别在于，把快速走子换成了神经网络来推理 pi 和 v。把pi存储在mct中，留给后面使用。并且在search的根节点时，引入 Dirichlet Noise 来增强探索性。








